{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94YvFTGrdHu7",
        "outputId": "49c29eff-977e-4d5f-d8c8-49815c5ab729",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: polars in /usr/local/lib/python3.11/dist-packages (1.21.0)\n",
            "Collecting xlsx2csv\n",
            "  Downloading xlsx2csv-0.8.4-py3-none-any.whl.metadata (5.7 kB)\n",
            "Downloading xlsx2csv-0.8.4-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: xlsx2csv\n",
            "Successfully installed xlsx2csv-0.8.4\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.2.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Downloading XlsxWriter-3.2.2-py3-none-any.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.1/165.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.2.2\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.11/dist-packages (1.21.0)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Collecting fastexcel\n",
            "  Downloading fastexcel-0.13.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from fastexcel) (18.1.0)\n",
            "Downloading fastexcel-0.13.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fastexcel\n",
            "Successfully installed fastexcel-0.13.0\n"
          ]
        }
      ],
      "source": [
        "#!pip install polars xlsx2csv\n",
        "#!pip install xlsxwriter\n",
        "#!pip install polars openpyxl\n",
        "#!pip install fastexcel\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample excel template creation with all columns"
      ],
      "metadata": {
        "id": "3LyNr89AQZNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "import subprocess\n",
        "\n",
        "# Path to the Excel file\n",
        "file_path = \"/content/Excelsheet.xlsx\"\n",
        "csv_path = \"/content/Excelsheet.csv\"\n",
        "\n",
        "# Convert Excel file (.xlsx) to CSV\n",
        "subprocess.run([\"xlsx2csv\", file_path, csv_path])\n",
        "\n",
        "# Read CSV into a Polars DataFrame\n",
        "df = pl.read_csv(csv_path)\n",
        "\n",
        "# Display column names\n",
        "print(df.columns)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7dl-Y8jQXuL",
        "outputId": "3c55f20a-6a01-4529-e34c-1cd6aac9a9df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Merchant Id', 'Store Number', 'GPR-Purchase Count', 'GPR-Purchase Amount', 'GPR-Purchase Charge Purchase Count', 'GPR-Purchase Charge Purchase Amount', 'GPR-Load Count', 'GPR-Load Amount', 'GPR-Purchase Charge Load Count', 'GPR-Purchase Charge Load Amount', 'GPR-Return Count', 'GPR-Return Amount', 'GPR-Commissions Paid Merchant Count', 'GPR-Commissions Paid Merchant Amount', 'GPR-Commissions Paid Program Owner Count', 'GPR-Commissions Paid Program Owner Amount', 'GPR-Commissions Paid FDC Count', 'GPR-Commissions Paid FDC Amount', 'GPR Liability-Commissions Disbursement Count', 'GPR Liability-Commissions Disbursement Amount', 'GPR-Liability Count', 'GPR-Liability Amount', 'GO Tag-Purchase Count', 'GO Tag-Purchase Amount', 'GO Tag-Purchase Charge Purchase Count', 'GO Tag-Purchase Charge Purchase Amount', 'GO Tag-Load Count', 'GO Tag-Load Amount', 'GO Tag-Purchase Charge Load Count', 'GO Tag-Purchase Charge Load Amount', 'GO Tag-Return Count', 'GO Tag-Return Amount', 'GO Tag-Commissions Paid Merchant Count', 'GO Tag-Commissions Paid Merchant Amount', 'GO Tag-Commissions Paid Program Owner Count', 'GO Tag-Commissions Paid Program Owner Amount', 'GO Tag-Commissions Paid FDC Count', 'GO Tag-Commissions Paid FDC Amount', 'GO Tag Liability-Commissions Disbursement Count', 'GO Tag Liability-Commissions Disbursement Amount', 'GO Tag-Liability Count', 'GO Tag-Liability Amount', 'Everywhere Card-Purchase Count', 'Everywhere Card-Purchase Amount', 'Everywhere Card-Purchase Charge Purchase Count', 'Everywhere Card-Purchase Charge Purchase Amount', 'Everywhere Card-Load Count', 'Everywhere Card-Load Amount', 'Everywhere Card-Purchase Charge Load Count', 'Everywhere Card-Purchase Charge Load Amount', 'Everywhere Card-Return Count', 'Everywhere Card-Return Amount', 'Everywhere Card-Commissions Paid Merchant Count', 'Everywhere Card-Commissions Paid Merchant Amount', 'Everywhere Card-Commissions Paid Program Owner Count', 'Everywhere Card-Commissions Paid Program Owner Amount', 'Everywhere Card-Commissions Paid FDC Count', 'Everywhere Card-Commissions Paid FDC Amount', 'Everywhere Card Liability-Commissions Disbursement Count', 'Everywhere Card Liability-Commissions Disbursement Amount', 'Everywhere Card-Liability Count', 'Everywhere Card-Liability Amount', 'Manual Adjustments Count', 'Manual Adjustments Amount', 'ACH Returns Count', 'ACH Returns Amount', 'ACH Rejects Count', 'ACH Rejects Amount', 'Not Settled Count', 'Not Settled Amount', 'Total Activity Count', 'Total Activity Amount']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter columns that contain 'count' in their name (case-insensitive)\n",
        "columns_with_count = [col for col in df.columns if 'count' in col.lower()]\n",
        "\n",
        "# Print the filtered column names\n",
        "print(\"Columns with 'count':\", columns_with_count)\n",
        "\n",
        "# Count the number of cleaned columns\n",
        "num_columns_with_count = len(columns_with_count)\n",
        "print(num_columns_with_count)\n",
        "\n",
        "# Clean the filtered columns by removing ' Count' and stripping leading/trailing spaces\n",
        "cleaned_columns = [col.replace(' Count', '').strip() for col in columns_with_count]\n",
        "\n",
        "# Print the cleaned column names\n",
        "print(\"Cleaned columns:\", cleaned_columns)\n",
        "\n",
        "# Count the number of cleaned columns\n",
        "num_cleaned_columns = len(cleaned_columns)\n",
        "print(num_cleaned_columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m25wavLIQYbH",
        "outputId": "f3e1b2b7-917f-4c1d-f783-16d83f78531f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns with 'count': ['GPR-Purchase Count', 'GPR-Purchase Charge Purchase Count', 'GPR-Load Count', 'GPR-Purchase Charge Load Count', 'GPR-Return Count', 'GPR-Commissions Paid Merchant Count', 'GPR-Commissions Paid Program Owner Count', 'GPR-Commissions Paid FDC Count', 'GPR Liability-Commissions Disbursement Count', 'GPR-Liability Count', 'GO Tag-Purchase Count', 'GO Tag-Purchase Charge Purchase Count', 'GO Tag-Load Count', 'GO Tag-Purchase Charge Load Count', 'GO Tag-Return Count', 'GO Tag-Commissions Paid Merchant Count', 'GO Tag-Commissions Paid Program Owner Count', 'GO Tag-Commissions Paid FDC Count', 'GO Tag Liability-Commissions Disbursement Count', 'GO Tag-Liability Count', 'Everywhere Card-Purchase Count', 'Everywhere Card-Purchase Charge Purchase Count', 'Everywhere Card-Load Count', 'Everywhere Card-Purchase Charge Load Count', 'Everywhere Card-Return Count', 'Everywhere Card-Commissions Paid Merchant Count', 'Everywhere Card-Commissions Paid Program Owner Count', 'Everywhere Card-Commissions Paid FDC Count', 'Everywhere Card Liability-Commissions Disbursement Count', 'Everywhere Card-Liability Count', 'Manual Adjustments Count', 'ACH Returns Count', 'ACH Rejects Count', 'Not Settled Count', 'Total Activity Count']\n",
            "35\n",
            "Cleaned columns: ['GPR-Purchase', 'GPR-Purchase Charge Purchase', 'GPR-Load', 'GPR-Purchase Charge Load', 'GPR-Return', 'GPR-Commissions Paid Merchant', 'GPR-Commissions Paid Program Owner', 'GPR-Commissions Paid FDC', 'GPR Liability-Commissions Disbursement', 'GPR-Liability', 'GO Tag-Purchase', 'GO Tag-Purchase Charge Purchase', 'GO Tag-Load', 'GO Tag-Purchase Charge Load', 'GO Tag-Return', 'GO Tag-Commissions Paid Merchant', 'GO Tag-Commissions Paid Program Owner', 'GO Tag-Commissions Paid FDC', 'GO Tag Liability-Commissions Disbursement', 'GO Tag-Liability', 'Everywhere Card-Purchase', 'Everywhere Card-Purchase Charge Purchase', 'Everywhere Card-Load', 'Everywhere Card-Purchase Charge Load', 'Everywhere Card-Return', 'Everywhere Card-Commissions Paid Merchant', 'Everywhere Card-Commissions Paid Program Owner', 'Everywhere Card-Commissions Paid FDC', 'Everywhere Card Liability-Commissions Disbursement', 'Everywhere Card-Liability', 'Manual Adjustments', 'ACH Returns', 'ACH Rejects', 'Not Settled', 'Total Activity']\n",
            "35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reading from txt files and writing into provided excel template"
      ],
      "metadata": {
        "id": "_ZhqydomQfpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "import openpyxl\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "# Path to the existing Excel file\n",
        "excel_path = \"/content/Output_data.xlsx\"\n",
        "\n",
        "def process_xml(file_path):\n",
        "    \"\"\"Reads XML from a .txt file without a root element and parses it.\"\"\"\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        xml_content = file.read()\n",
        "        wrapped_xml = f\"<root>{xml_content}</root>\"  # Add missing root element if needed\n",
        "        root = ET.fromstring(wrapped_xml)\n",
        "\n",
        "    data_dict = {}\n",
        "\n",
        "    for item in root.findall(\"ValueLinkLineItem\"):\n",
        "        merchant_id = item.find(\"merchantNumber\").text if item.find(\"merchantNumber\") is not None else \"Unknown\"\n",
        "        store_number = item.find(\"altMerchantNumber\").text if item.find(\"altMerchantNumber\") is not None else \"Unknown\"\n",
        "        category = item.find(\"category\").text if item.find(\"category\") is not None else \"Unknown\"\n",
        "        amount = float(item.find(\"amount/FSNDollarUS\").attrib[\"amount\"]) if item.find(\"amount/FSNDollarUS\") is not None else 0.0\n",
        "        count = int(item.find(\"count\").text) if item.find(\"count\") is not None else 0\n",
        "\n",
        "        key = (merchant_id, store_number)\n",
        "\n",
        "        if key not in data_dict:\n",
        "            data_dict[key] = {}\n",
        "\n",
        "        # Aggregate duplicate categories within the same XML file\n",
        "        data_dict[key][f\"{category} Count\"] = data_dict[key].get(f\"{category} Count\", 0) + count\n",
        "        data_dict[key][f\"{category} Amount\"] = data_dict[key].get(f\"{category} Amount\", 0.0) + amount\n",
        "\n",
        "    return data_dict\n",
        "\n",
        "# Read existing Excel file to get the column structure\n",
        "if os.path.exists(excel_path):\n",
        "    existing_df = pl.read_excel(excel_path).fill_null(0)  # Ensure no null values\n",
        "else:\n",
        "    raise FileNotFoundError(f\"Excel file '{excel_path}' not found.\")\n",
        "\n",
        "# Get column names from the existing file\n",
        "columns = existing_df.columns\n",
        "\n",
        "# Identify count and amount columns dynamically\n",
        "count_columns = [col for col in columns if \" Count\" in col and col != \"Total Activity Count\"]\n",
        "amount_columns = [col for col in columns if \" Amount\" in col and col != \"Total Activity Amount\"]\n",
        "\n",
        "# Ensure \"Count\" and \"Amount\" pairs remain together\n",
        "column_pairs = [(count_col, count_col.replace(\" Count\", \" Amount\")) for count_col in count_columns]\n",
        "\n",
        "# Process multiple XML files and update values\n",
        "file_paths = [\"/content/original_1.txt\", \"/content/original_2.txt\", \"/content/original_3.txt\", \"/content/original_4.txt\"]\n",
        "\n",
        "aggregated_data = {}\n",
        "\n",
        "# Process each XML file and aggregate data separately\n",
        "for file_path in file_paths:\n",
        "    xml_data = process_xml(file_path)\n",
        "\n",
        "    for (merchant_id, store_number), values in xml_data.items():\n",
        "        key = (merchant_id, store_number)\n",
        "\n",
        "        if key not in aggregated_data:\n",
        "            aggregated_data[key] = {col: 0 for col in columns if col not in [\"Merchant Id\", \"Store Number\"]}\n",
        "\n",
        "        # Sum values from XML into existing merchant-store keys\n",
        "        for col, value in values.items():\n",
        "            if col in aggregated_data[key]:  # Only update if the column exists in the Excel template\n",
        "                aggregated_data[key][col] += value\n",
        "\n",
        "# Convert aggregated data into a Polars DataFrame, ensuring all unique rows are retained\n",
        "updated_df = pl.DataFrame(\n",
        "    [(key[0], key[1]) + tuple(values.get(col, 0) for col in columns[2:]) for key, values in aggregated_data.items()],\n",
        "    schema=[(\"Merchant Id\", pl.Utf8), (\"Store Number\", pl.Utf8)] + [(col, pl.Int64 if \" Count\" in col else pl.Float64) for col in columns[2:]],\n",
        "    strict=False  # Allow mixed types if needed\n",
        ")\n",
        "\n",
        "# If the existing file is empty, use updated_df as the base structure\n",
        "if existing_df.height == 0:\n",
        "    merged_df = updated_df\n",
        "else:\n",
        "    # Merge using \"outer\" to retain all unique Merchant Id & Store Numbers\n",
        "    merged_df = existing_df.join(updated_df, on=[\"Merchant Id\", \"Store Number\"], how=\"outer\").fill_null(0)\n",
        "\n",
        "# Calculate Total Activity Count & Amount\n",
        "merged_df = merged_df.with_columns(\n",
        "    pl.sum_horizontal(count_columns).alias(\"Total Activity Count\").cast(pl.Int64),\n",
        "    pl.sum_horizontal(amount_columns).alias(\"Total Activity Amount\").cast(pl.Float64)\n",
        ")\n",
        "\n",
        "# Ensure output column order matches input file\n",
        "merged_df = merged_df.select(columns)  # Preserve column order\n",
        "# Write DataFrame to Excel (default sheet = \"Sheet1\")\n",
        "merged_df.write_excel(excel_path)\n",
        "\n",
        "# Rename \"Sheet1\" to \"xml_data\"\n",
        "wb = openpyxl.load_workbook(excel_path)\n",
        "if \"Sheet1\" in wb.sheetnames:\n",
        "    ws = wb[\"Sheet1\"]\n",
        "    ws.title = \"xml_data\"  # Rename the sheet\n",
        "wb.save(excel_path)\n",
        "wb.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHwHkMKtwU5b",
        "outputId": "3e6bb038-6889-40cb-9011-97bdf49f1313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-49-599a677b7fbe>:73: DataOrientationWarning: Row orientation inferred during DataFrame construction. Explicitly specify the orientation by passing `orient=\"row\"` to silence this warning.\n",
            "  updated_df = pl.DataFrame(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Alternative to keep xml_data as tab name and keep the formatting away with pandas"
      ],
      "metadata": {
        "id": "7i7kd1wVDNKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Alternative to keep the sheet name as xml_data\n",
        "# Save the updated DataFrame back to the same Excel file\n",
        "import pandas as pd\n",
        "\n",
        "# Convert Polars DataFrame to Pandas\n",
        "merged_df_pandas = merged_df.to_pandas()\n",
        "\n",
        "# Write to Excel using Pandas to retain sheet structure\n",
        "with pd.ExcelWriter(excel_path, mode=\"a\", if_sheet_exists=\"overlay\", engine=\"openpyxl\") as writer:\n",
        "    merged_df_pandas.to_excel(writer, sheet_name=\"xml_data\", index=False)"
      ],
      "metadata": {
        "id": "DIHjDXrSCulb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read the Output Excel"
      ],
      "metadata": {
        "id": "nwkfjAKnQshp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the updated Excel file into a Polars DataFrame\n",
        "final_df = pl.read_excel(excel_path)\n",
        "\n",
        "# Print the full DataFrame without truncation\n",
        "print(final_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEbKNUmrjJkN",
        "outputId": "08f42c9e-c504-4c13-edd0-40897f37b7db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (4, 72)\n",
            "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
            "│ Merchant  ┆ Store     ┆ GPR-Purch ┆ GPR-Purch ┆ … ┆ Not       ┆ Not       ┆ Total     ┆ Total    │\n",
            "│ Id        ┆ Number    ┆ ase Count ┆ ase       ┆   ┆ Settled   ┆ Settled   ┆ Activity  ┆ Activity │\n",
            "│ ---       ┆ ---       ┆ ---       ┆ Amount    ┆   ┆ Count     ┆ Amount    ┆ Count     ┆ Amount   │\n",
            "│ str       ┆ str       ┆ i64       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
            "│           ┆           ┆           ┆ i64       ┆   ┆ i64       ┆ i64       ┆ i64       ┆ i64      │\n",
            "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
            "│ WMUSPAYLO ┆ 000004541 ┆ 0         ┆ 0         ┆ … ┆ 0         ┆ 0         ┆ 4         ┆ -12300   │\n",
            "│ CS        ┆ 32        ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
            "│ WMUSPAYLO ┆ 000002452 ┆ 0         ┆ 0         ┆ … ┆ 0         ┆ 0         ┆ 2         ┆ -90000   │\n",
            "│ CS        ┆ 65        ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
            "│ WMUSPAYLO ┆ 000002468 ┆ 0         ┆ 0         ┆ … ┆ 0         ┆ 0         ┆ 1         ┆ -13000   │\n",
            "│ CS        ┆ 98        ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
            "│ WMUSPAYLO ┆ 000002441 ┆ 4         ┆ -4300     ┆ … ┆ 2         ┆ -140      ┆ 84        ┆ -146     │\n",
            "│ CS        ┆ 32        ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
            "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XKdmsWA7zPye"
      }
    }
  ]
}